---
{"dg-publish":true,"permalink":"/ai-enablement/eu-ai-act/eu-artificial-intelligence-act-baseline/","title":["EU Artificial Intelligence Act (EU AI Act)"]}
---


The EU AI Act, formally adopted in July 2024, is the world’s first comprehensive legal framework regulating artificial intelligence. It aims to ensure that AI systems used in the EU are safe, transparent, ethically aligned, and respect fundamental rights. The Act is comparable in scope and ambition to the GDPR and is expected to become a global benchmark for AI regulation.

#### **Scope and Applicability**

The Act applies to:
- Providers, deployers, importers, and distributors of AI systems in the EU.
- Organisations outside the EU if their AI systems affect people within the EU.
- Both public and private sector entities.

It covers AI systems defined broadly as software developed using machine learning, logic-based, or statistical approaches that can generate outputs such as predictions, recommendations, or decisions.

#### **Risk-Based Classification**

The Act introduces a four-tier risk classification system:

1. **Unacceptable Risk**: These AI systems are prohibited. Examples include:
    - Social scoring by governments.
    - Real-time biometric identification in public spaces (with narrow exceptions).
    - Manipulative or exploitative AI targeting vulnerable groups.

2. **High Risk**: These systems are heavily regulated and must meet strict requirements. They include AI used in:
    - Critical infrastructure (e.g., transport, energy).
    - Education and vocational training (e.g., exam scoring).
    - Employment (e.g., CV screening).
    - Law enforcement and border control.
    - Access to essential services (e.g., credit scoring, healthcare).
    
    Obligations include:
    - Risk management and data governance.
    - Human oversight and transparency.
    - Robust documentation and record-keeping.
    - Registration in the EU AI Database.

3. **Limited Risk**: These systems must comply with transparency obligations. Users must be informed when:
    - They are interacting with an AI system (e.g., chatbots).
    - Content is AI-generated (e.g., deepfakes).
    - Emotion recognition or biometric categorisation is used.

4. **Minimal or No Risk**: These systems are largely unregulated, though voluntary codes of conduct are encouraged.
    
#### **Governance and Enforcement**

The Act establishes a European AI Office to coordinate enforcement and provide guidance. Each EU Member State will designate a national supervisory authority. A Scientific Panel of independent experts will advise on general-purpose AI (GPAI) and systemic risks.

#### **General-Purpose AI (GPAI) and Foundation Models**

The Act introduces specific rules for **GPAI systems** (e.g., large language models). Developers of GPAI must:
- Provide detailed technical documentation.
- Ensure compliance with EU copyright law.
- Publish summaries of training data.
- Implement risk mitigation measures, especially for systemic GPAI models with significant impact potential.

#### **Timeline and Implementation**

**12 July 2024**: Official publication in the EU’s Official Journal.
**2025–2026**: Gradual implementation begins.
**2026**: Full enforcement expected, with different provisions entering into force at staggered intervals.

#### **Compliance Considerations for DPOs**

As a DPO, key responsibilities include:
- Ensuring data protection impact assessments (DPIAs) are updated to reflect AI risks.
- Coordinating with technical teams to verify data governance and human oversight mechanisms.
- Monitoring third-party AI providers for compliance.
- Supporting transparency and communication with data subjects regarding AI use.
- Preparing for audits and documentation requirements under the Act.
