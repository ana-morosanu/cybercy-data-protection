---
{"dg-publish":true,"permalink":"/ai-enablement/eu-ai-act/prohibited-ai-practices-article-5/","title":["Article 5"]}
---


Article 5 outlines a list of **AI practices that are completely banned** within the EU. These are considered so harmful to people’s rights, safety, or dignity that they are not allowed under any circumstances. The goal is to **protect fundamental rights** and prevent the misuse of AI in ways that could lead to manipulation, exploitation, or unjust surveillance.

### Categories of Prohibited AI Practices

1. **Subliminal Manipulation**  
    AI systems that use subliminal techniques (i.e. below the threshold of conscious perception) to distort a person’s behaviour in a way that could cause physical or psychological harm are banned.  
    _Example: An AI system that subtly manipulates users into making harmful decisions without them realising it._
    
2. **Exploitation of Vulnerabilities**  
    AI systems that exploit vulnerabilities of specific groups, such as children, people with disabilities, or those in economically or socially vulnerable situations, are prohibited if they could cause harm.  
    _Example: An AI chatbot targeting children to influence their behaviour or extract personal data._
    
3. **Social Scoring by Public Authorities**  
    The use of AI by public authorities to evaluate or classify people based on their behaviour, social status, or personal characteristics (i.e. “social scoring”) is banned if it leads to unfair or disproportionate treatment.  
    _Example: A government system that denies services or opportunities based on a person’s lifestyle or online activity._
    
4. **Real-Time Remote Biometric Identification in Public Spaces (with exceptions)**  
    The use of AI for real-time biometric identification (like facial recognition) in public spaces by law enforcement is generally prohibited, **unless** it meets strict exceptions, such as:
    - Searching for missing persons
    - Preventing imminent terrorist threats
    - Identifying suspects of serious crimes
    
    Even in these cases, the use must be authorised by law, proportionate, and subject to safeguards.


This article reflects the EU’s strong stance on human dignity, privacy, and freedom. It recognises that some uses of AI are simply too risky or unethical to be allowed, regardless of potential benefits. It also sets a clear red line for developers and deployers of AI systems: if your system falls into one of these categories, it cannot be used in the EU.

By banning these practices, the EU aims to build public trust in AI and ensure that innovation does not come at the cost of fundamental rights.
