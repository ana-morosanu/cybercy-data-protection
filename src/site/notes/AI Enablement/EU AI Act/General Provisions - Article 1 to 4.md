---
{"dg-publish":true,"permalink":"/ai-enablement/eu-ai-act/general-provisions-article-1-to-4/","title":["Article 1 - 4"]}
---


### **Article 1 – Subject Matter**

This article sets the foundation for the entire regulation. It explains that the AI Act is designed to create a common legal framework across the EU for the development, marketing, and use of AI systems. The regulation aims to ensure that AI is trustworthy, human-centric, and aligned with EU values.

The Act is not just about safety, it also protects fundamental rights, such as privacy, non-discrimination, and freedom of expression. It also supports democracy, the rule of law, and environmental sustainability. Importantly, it seeks to balance innovation and protection, ensuring that AI can thrive in the EU without compromising public trust.

The regulation also aims to prevent fragmentation across Member States by ensuring that AI systems can move freely across borders within the EU. This means that once an AI system is compliant in one country, it should be accepted across the entire Union.

Finally, the article highlights that the regulation is meant to foster innovation by providing legal certainty and encouraging the development of safe and ethical AI technologies.

### **Article 2 – Scope**

This article defines who and what the regulation applies to. It covers:
- Providers (those who develop or place AI systems on the market),
- Deployers (those who use AI systems),
- Importers and distributors, and
- Users of AI systems within the EU.

It also applies to AI systems used outside the EU if their output affects people inside the EU, this is known as the extraterritorial effect.

However, the regulation does not apply to AI systems used exclusively for:
- Military or national security purposes, or
- Pure research and development that is not placed on the market or put into service.

This scope ensures that the regulation is broad enough to cover real-world use cases, but narrow enough to avoid interfering with sensitive or early-stage innovation.

### **Article 3 – Definitions**

This article provides the key definitions used throughout the regulation. The most important is the definition of an AI system, which is described as a machine-based system that can, for a given set of objectives, generate outputs such as predictions, recommendations, or decisions that influence real or virtual environments.

Other important definitions include:
- Provider: The entity that develops or markets the AI system.
- Deployer: The person or organisation using the AI system.
- High-risk AI system: Systems that pose significant risks to health, safety, or fundamental rights (e.g. in employment, education, law enforcement).
- Biometric categorisation, emotion recognition, and general-purpose AI models are also defined.

These definitions are crucial because they determine who has legal responsibilities and what obligations apply under the Act.

### **Article 4 – AI Literacy**

This article introduces a new legal concept: AI literacy. It recognises that for AI to be used responsibly, people need to understand how it works.

Member States are required to promote education and training on AI for:
- The general public,
- Workers and employers,
- Public authorities, and
- Professionals who interact with or oversee AI systems.

The goal is to ensure that people can use AI safely, understand its limitations, and make informed decisions when interacting with AI technologies. This is especially important for those in roles of oversight or accountability.

AI literacy is not just about technical skills, it also includes understanding ethical implications, bias, transparency, and human oversight.
